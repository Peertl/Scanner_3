<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>3D Parcel Master AI-Lines</title>
    <script async src="https://docs.opencv.org/4.5.4/opencv.js" type="text/javascript"></script>
    <style>
        body { margin: 0; background: #000; font-family: sans-serif; overflow: hidden; color: white; }
        #container { position: relative; width: 100vw; height: 100vh; display: flex; justify-content: center; align-items: center; }
        video { position: absolute; width: 100%; height: 100%; object-fit: cover; opacity: 0; }
        canvas { position: absolute; width: 100%; height: 100%; object-fit: cover; z-index: 5; }
        
        #ui-top { position: absolute; top: 0; width: 100%; z-index: 20; background: rgba(0,0,0,0.85); padding: 20px 0; text-align: center; border-bottom: 2px solid #007bff; }
        .status { font-size: 1.2rem; font-weight: bold; margin-bottom: 10px; text-transform: uppercase; }
        .progress-bg { width: 80%; background: #333; height: 10px; margin: 0 auto; border-radius: 5px; }
        #progress-fill { width: 0%; height: 100%; background: #28a745; border-radius: 5px; transition: width 0.2s; }
        
        .controls { position: absolute; bottom: 40px; width: 100%; z-index: 20; display: flex; flex-direction: column; align-items: center; gap: 15px; }
        button { padding: 20px 50px; font-size: 1.3rem; border-radius: 50px; border: none; font-weight: bold; color: white; cursor: pointer; }
        #btn-measure { background: #007bff; width: 75%; box-shadow: 0 4px 15px rgba(0,123,255,0.4); }
        #btn-reset { background: #444; font-size: 0.9rem; padding: 12px 25px; }
        #loading { position: fixed; inset: 0; background: #111; z-index: 100; display: flex; flex-direction: column; justify-content: center; align-items: center; }
    </style>
</head>
<body>

<div id="loading">
    <div style="font-size: 3rem; margin-bottom: 15px;">üîç</div>
    <p>KI-Linien-Erkennung wird geladen...</p>
</div>

<div id="container">
    <video id="videoInput" playsinline muted></video>
    <canvas id="canvasOutput"></canvas>
</div>

<div id="ui-top">
    <div id="status">Warte auf Kamera...</div>
    <div class="progress-bg" id="p-bar-container">
        <div id="progress-fill"></div>
    </div>
</div>

<div class="controls">
    <button id="btn-measure" onclick="onMeasureClick()">PAKET VERMESSEN</button>
    <button id="btn-reset" onclick="resetCalibration()">NEU KALIBRIEREN</button>
</div>

<script>
let state = 'SCAN';
let pxPerCm = localStorage.getItem('px_cm') ? parseFloat(localStorage.getItem('px_cm')) : null;
let calibSamples = [];
const REQUIRED_SAMPLES = 40;

const video = document.getElementById('videoInput');
const canvas = document.getElementById('canvasOutput');
const ctx = canvas.getContext('2d');
const statusText = document.getElementById('status');
const btnMeasure = document.getElementById('btn-measure');
const progressFill = document.getElementById('progress-fill');

let isStreaming = false;
let lastResult = null;

function onOpenCvReady() {
    document.getElementById('loading').style.display = 'none';
    initCamera();
}

async function initCamera() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
            video: { facingMode: "environment", width: 1280, height: 720 } 
        });
        video.srcObject = stream;
        video.play();
        video.oncanplay = () => {
            if (!isStreaming) {
                isStreaming = true;
                state = pxPerCm ? 'READY' : 'SCAN';
                updateUI();
                processFrame();
            }
        };
    } catch (e) {
        alert("Kamera-Fehler");
    }
}

function updateUI() {
    if (state === 'SCAN') {
        statusText.innerText = "Phase 1: Blatt scannen";
        statusText.style.color = "#ffc107";
        btnMeasure.style.display = "none";
        document.getElementById('p-bar-container').style.display = "block";
    } else if (state === 'READY') {
        statusText.innerText = "Phase 2: Paket anvisieren";
        statusText.style.color = "#00ff00";
        btnMeasure.style.display = "block";
        btnMeasure.innerText = "PAKET VERMESSEN";
        document.getElementById('p-bar-container').style.display = "none";
    } else {
        statusText.innerText = "ERGEBNIS";
        btnMeasure.innerText = "ZUR√úCK";
    }
}

function resetCalibration() {
    localStorage.removeItem('px_cm');
    pxPerCm = null;
    calibSamples = [];
    state = 'SCAN';
    updateUI();
}

function onMeasureClick() {
    if (state === 'READY') {
        performAIBoxDetection();
        state = 'RESULT';
    } else {
        state = 'READY';
        lastResult = null;
    }
    updateUI();
}

function processFrame() {
    if (!isStreaming || video.videoWidth === 0) {
        requestAnimationFrame(processFrame);
        return;
    }

    if (state === 'RESULT' && lastResult) {
        ctx.putImageData(lastResult, 0, 0);
        requestAnimationFrame(processFrame);
        return;
    }

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    let src = cv.imread(canvas);
    let gray = new cv.Mat();
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

    if (state === 'SCAN') {
        detectA4(gray, src);
    }

    cv.imshow('canvasOutput', src);
    src.delete(); gray.delete();
    requestAnimationFrame(processFrame);
}

function detectA4(gray, src) {
    let edged = new cv.Mat();
    cv.Canny(gray, edged, 50, 150);
    let contours = new cv.MatVector();
    let hierarchy = new cv.Mat();
    cv.findContours(edged, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

    for (let i = 0; i < contours.size(); ++i) {
        let cnt = contours.get(i);
        if (cv.contourArea(cnt) > 10000) {
            let approx = new cv.Mat();
            cv.approxPolyDP(cnt, approx, 0.02 * cv.arcLength(cnt, true), true);
            if (approx.rows === 4) {
                let pts = [];
                for(let j=0; j<4; j++) pts.push({x: approx.data32S[j*2], y: approx.data32S[j*2+1]});
                
                ctx.strokeStyle = "#00ff00";
                ctx.lineWidth = 6;
                ctx.beginPath();
                ctx.moveTo(pts[0].x, pts[0].y);
                for(let p of pts) ctx.lineTo(p.x, p.y);
                ctx.closePath();
                ctx.stroke();

                let d1 = Math.hypot(pts[0].x - pts[1].x, pts[0].y - pts[1].y);
                let d2 = Math.hypot(pts[1].x - pts[2].x, pts[1].y - pts[2].y);
                calibSamples.push(Math.max(d1, d2) / 29.7);

                progressFill.style.width = (calibSamples.length / REQUIRED_SAMPLES * 100) + "%";

                if (calibSamples.length >= REQUIRED_SAMPLES) {
                    pxPerCm = calibSamples.sort((a,b) => a-b)[20];
                    localStorage.setItem('px_cm', pxPerCm);
                    state = 'READY';
                    updateUI();
                }
            }
            approx.delete();
        }
    }
    edged.delete(); contours.delete(); hierarchy.delete();
}

function performAIBoxDetection() {
    let src = cv.imread(canvas);
    let gray = new cv.Mat();
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
    
    // KONTRAST BOOST (Verbessert braune Kartons auf Holz)
    let clahe = new cv.CLAHE(2.0, new cv.Size(8, 8));
    clahe.apply(gray, gray);
    clahe.delete();

    // LINIERERKENNUNG (Hough Lines)
    let edged = new cv.Mat();
    cv.Canny(gray, edged, 50, 200);
    let lines = new cv.Mat();
    // Probabilistic Hough Transform
    cv.HoughLinesP(edged, lines, 1, Math.PI / 180, 50, 50, 10);

    let allEdges = [];
    for (let i = 0; i < lines.rows; ++i) {
        let x1 = lines.data32S[i * 4];
        let y1 = lines.data32S[i * 4 + 1];
        let x2 = lines.data32S[i * 4 + 2];
        let y2 = lines.data32S[i * 4 + 3];
        
        let dx = x2 - x1;
        let dy = y2 - y1;
        let angle = Math.atan2(dy, dx) * 180 / Math.PI;
        if (angle < 0) angle += 180;
        let dist = Math.hypot(dx, dy) / pxPerCm;

        if (dist > 3) {
            allEdges.push({p1: {x:x1, y:y1}, p2: {x:x2, y:y2}, dist, angle});
        }
    }

    // Gruppierung nach 3D-Achsen
    let h_lines = allEdges.filter(e => e.angle > 70 && e.angle < 110);
    let l_lines = allEdges.filter(e => (e.angle >= 0 && e.angle <= 45) || (e.angle >= 135 && e.angle <= 180));
    let b_lines = allEdges.filter(e => !h_lines.includes(e) && !l_lines.includes(e));

    // Zeichne die jeweils l√§ngste Linie pro Gruppe
    if (h_lines.length > 0) {
        let best = h_lines.sort((a,b) => b.dist - a.dist)[0];
        draw3DLine(best.p1, best.p2, best.dist, "H", "#ffff00");
    }
    if (l_lines.length > 0) {
        let best = l_lines.sort((a,b) => b.dist - a.dist)[0];
        draw3DLine(best.p1, best.p2, best.dist, "L", "#00ff00");
    }
    if (b_lines.length > 0) {
        let best = b_lines.sort((a,b) => b.dist - a.dist)[0];
        draw3DLine(best.p1, best.p2, best.dist, "B", "#007bff");
    }

    lastResult = ctx.getImageData(0, 0, canvas.width, canvas.height);
    src.delete(); gray.delete(); edged.delete(); lines.delete();
}

function draw3DLine(p1, p2, dist, label, color) {
    ctx.strokeStyle = color;
    ctx.lineWidth = 12;
    ctx.lineCap = "round";
    ctx.beginPath();
    ctx.moveTo(p1.x, p1.y);
    ctx.lineTo(p2.x, p2.y);
    ctx.stroke();

    let mx = (p1.x + p2.x) / 2;
    let my = (p1.y + p2.y) / 2;
    ctx.fillStyle = "rgba(0,0,0,0.85)";
    ctx.font = "bold 28px Arial";
    let text = label + ": " + dist.toFixed(1) + " cm";
    let tw = ctx.measureText(text).width;
    ctx.fillRect(mx - tw/2 - 10, my - 25, tw + 20, 45);
    ctx.fillStyle = color;
    ctx.fillText(text, mx - tw/2, my + 8);
}

window.onload = () => {
    if (typeof cv !== 'undefined' && cv.Mat) onOpenCvReady();
    else cv['onRuntimeInitialized'] = onOpenCvReady;
};
</script>
</body>
</html>